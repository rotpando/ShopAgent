# Copy this file to .env and fill in your values

# LLM Provider Configuration
# Choose one: openai, groq, inference_net, together, huggingface, ollama
LLM_PROVIDER=groq

# ===== GROQ (FREE & FAST) - RECOMMENDED =====
# Sign up at: https://groq.com (completely free)
GROQ_API_KEY=your-groq-api-key-here

# ===== OPTIONAL: OpenAI (if you prefer to pay) =====
# OPENAI_API_KEY=your-openai-api-key-here

# ===== FREE ALTERNATIVES =====

# Hugging Face (Free tier)
# Sign up: https://huggingface.co
HF_API_KEY=your-hf-token-here

# ===== CHEAP ALTERNATIVES =====

# Inference.net (95% cheaper than OpenAI)
# Sign up: https://inference.net - $25 free credits
INFERENCE_API_KEY=your-inference-api-key-here

# Together.ai (80% cheaper than OpenAI)
# Sign up: https://together.ai - $25 free credits
TOGETHER_API_KEY=your-together-api-key-here

# ===== LOCAL OPTION =====
# Ollama (100% free, runs locally)
# Install: https://ollama.com
# No API key needed for local usage

# ===== OPTIONAL: Redis Configuration =====
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0

# ===== OPTIONAL: Streamlit Configuration =====
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=0.0.0.0 